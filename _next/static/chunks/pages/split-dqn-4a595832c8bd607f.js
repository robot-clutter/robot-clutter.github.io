(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[817],{56327:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/split-dqn",function(){return n(22339)}])},67565:function(e,t,n){"use strict";var i=n(46189),o={slug:"split-dqn",title:"Split Deep Q-Learning for Robust Object Singulation",year:"2020",image:{src:"PUBLIC_FOLDER",path:"split_dqn_header_image.jpg",width:1040,height:975},journal:"IEEE International Conference on Robotics and Automation",journal_small:"ICRA",authors:[i.c.IASON_SARANTOPOULOS,i.c.MARIOS_KIATOS,i.c.ZOE_DOULGERI,i.c.SOTIRIS_MALASIOTIS],abstract:"Extracting a known target object from a pile of other objects in a cluttered environment is a challenging robotic manipulation task encountered in many robotic applications. In such conditions, the target object touches or is covered by adjacent obstacle objects, thus rendering traditional grasping techniques ineffective. In this paper, we propose a pushing policy aiming at singulating the target object from its surrounding clutter, by means of lateral pushing movements of both the neighboring objects and the target object until sufficient 'grasping room' has been achieved. To achieve the above goal we employ reinforcement learning and particularly Deep Q-learning (DQN) to learn optimal push policies by trial and error. A novel Split DQN is proposed to improve the learning rate and increase the modularity of the algorithm. Experiments show that although learning is performed in a simulated environment the transfer of learned policies to a real environment is effective thanks to robust feature selection. Finally, we demonstrate that the modularity of the algorithm allows the addition of extra primitives without retraining the model from scratch.",videos:["https://www.youtube.com/watch?v=ef1MKgVkN0E"],code:[{link:"https://ieeexplore.ieee.org/document/9196647",alias:"IEEEXplore",type:"manuscript"},{link:"https://arxiv.org/abs/1909.08105",alias:"arXiv",type:"manuscript"},{link:"https://github.com/robot-clutter/robot-clutter.github.io",alias:"Source Code",type:"code",disabled:!0,disabledText:"Source code is not available yet. Please check again later."}],bib:"@inproceedings{splitdqn20,\n  title={Split Deep Q-Learning for Robust Object Singulation},\n  author={Sarantopoulos, Iason and Kiatos, Marios and Doulgeri, Zoe and Malassiotis, Sotiris},\n  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},\n  pages={6225--6231},\n  year={2020},\n  organization={IEEE}\n}"};t.Z=o},22339:function(e,t,n){"use strict";n.r(t);var i=n(85893),o=n(9008),a=n.n(o),r=n(10223),s=n(67565),l=n(49906);function c(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function u(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},i=Object.keys(n);"function"===typeof Object.getOwnPropertySymbols&&(i=i.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),i.forEach((function(t){c(e,t,n[t])}))}return e}var h=function(){return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(a(),{children:(0,i.jsx)("title",{children:s.Z.title})}),(0,i.jsx)(l.Z,u({},s.Z))]})};h.layout=r.Z,t.default=h}},function(e){e.O(0,[771,947,340,76,774,888,179],(function(){return t=56327,e(e.s=t);var t}));var t=e.O();_N_E=t}]);