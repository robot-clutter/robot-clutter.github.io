_N_E=(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[14],{QjEM:function(e,t,r){"use strict";r.r(t);var n=r("nKUr"),i=r("rePB"),o=r("g4pe"),a=r.n(o),s=r("8wFF"),l=r("iSez"),c=r("yjRv");function u(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function d(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?u(Object(r),!0).forEach((function(t){Object(i.a)(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):u(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}var h=function(){return Object(n.jsxs)(n.Fragment,{children:[Object(n.jsx)(a.a,{children:Object(n.jsx)("title",{children:l.a.title})}),Object(n.jsx)(c.a,d({},l.a))]})};h.layout=s.a,t.default=h},aMV0:function(e,t,r){(window.__NEXT_P=window.__NEXT_P||[]).push(["/modular-rl",function(){return r("QjEM")}])},iSez:function(e,t,r){"use strict";var n=r("72Ke"),i={slug:"modular-rl",title:"Total Singulation with Modular Reinforcement Learning",image:{src:"PUBLIC_FOLDER",path:"modular_rl_header_image.png",width:1040,height:975},type:"IEEE Robotics and Automation Letters (2021)",authors:[n.a.IASON_SARANTOPOULOS,n.a.MARIOS_KIATOS,n.a.ZOE_DOULGERI,n.a.SOTIRIS_MALASIOTIS],abstract:"Prehensile robotic grasping of a target object in clutter is challenging because, in such conditions, the target touches other objects, resulting to the lack of collision free grasp affordances. To address this problem, we propose a modular reinforcement learning method which uses continuous actions to totally singulate the target object from its surrounding clutter. A high level policy selects between pushing primitives, which are learned separately. Prior knowledge is effectively incorporated into learning, through action primitives and feature selection increasing sample efficiency. Experiments demonstrate that the proposed method considerably outperforms the state-of-the-art methods in the singulation task. Furthermore, although training is performed in simulation the learned policy is robustly transferred to a real environment without a significant drop in success rate. Finally, singulation tasks in different environments are addressed by easily adding a new primitive and by retraining only the high level policy.",videos:["https://www.youtube.com/watch?v=RZlDe-v3bok"],code:[{link:"https://ieeexplore.ieee.org/document/9363569",alias:"IEEEXplore",type:"manuscript"},{link:"https://github.com/robot-clutter/robot-clutter.github.io",alias:"Source Code",type:"code",disabled:!0,disabledText:"Source code is not available yet. Please check again later."}],bib:"@ARTICLE{modularrl21,\n  author={I. {Sarantopoulos} and M. {Kiatos} and Z. {Doulgeri} and S. {Malassiotis}},\n  journal={IEEE Robotics and Automation Letters}, \n  title={Total Singulation with Modular Reinforcement Learning}, \n  year={2021},\n  volume={},\n  number={},\n  pages={1-1},\n  doi={10.1109/LRA.2021.3062295}}"};t.a=i}},[["aMV0",0,2,6,1,3,4,5]]]);